import streamlit as st
import json
import re
import pandas as pd
from PyPDF2 import PdfReader
from openai import OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ ‡é¢˜
st.title("ğŸ¤– ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹ (My Knowledge Bot)")

# å·¦ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ“„ æ–‡æ¡£ä¸Šä¼ ")
    
    # æ–‡ä»¶ä¸Šä¼ å™¨
    uploaded_file = st.file_uploader(
        "ä¸Šä¼  PDF æ–‡æ¡£",
        type=["pdf"],
        help="æ”¯æŒä¸Šä¼  PDF æ ¼å¼çš„æ–‡æ¡£"
    )
    
    # æç¤ºæ–‡å­—
    st.caption("è¯·ä¸Šä¼ ä½ çš„æ–‡æ¡£ï¼Œæˆ‘ä¼šåŸºäºå®ƒå›ç­”é—®é¢˜ã€‚")
    
    # å¦‚æœä¸Šä¼ äº†æ–‡ä»¶ï¼Œæ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    if uploaded_file is not None:
        st.success(f"âœ… å·²ä¸Šä¼ : {uploaded_file.name}")
        st.info(f"æ–‡ä»¶å¤§å°: {uploaded_file.size / 1024:.2f} KB")

# ä¸»åŒºåŸŸ
st.divider()

# ä» Streamlit Secrets è¯»å– API Key
try:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
except KeyError:
    api_key = None
    st.error("âš ï¸ ç®¡ç†å‘˜æœªé…ç½®å¯†é’¥")

# PDF è§£æå’Œå‘é‡åŒ–é€»è¾‘
if uploaded_file is not None:
    try:
        with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
            # è¯»å– PDF æ–‡ä»¶
            pdf_reader = PdfReader(uploaded_file)
            
            # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()
            
            # æ–‡æœ¬åˆ‡ç‰‡
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50,  # <--- åŠ ä¸Šè¿™ä¸ªï¼
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"] # å°½é‡åœ¨å¥å·å¤„åˆ‡åˆ†
            )
            chunks = text_splitter.split_text(text)
            
            # å‘é‡åŒ–
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2"
            )
            
            # åˆ›å»ºå‘é‡ç´¢å¼•
            vectorstore = FAISS.from_texts(chunks, embeddings)
            
            # ä¿å­˜åˆ° session_stateï¼Œé˜²æ­¢åˆ·æ–°ä¸¢å¤±
            st.session_state.vectorstore = vectorstore
            
            # æ˜¾ç¤ºæˆåŠŸæç¤º
            st.success(f"âœ… æˆåŠŸå»ºç«‹ç´¢å¼•ï¼æ–‡æ¡£å·²åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µã€‚")
    
    except Exception as e:
        st.error(f"âŒ å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")

# ç»“æ„åŒ–æ•°æ®æå–åŠŸèƒ½
if "vectorstore" in st.session_state and api_key:
    st.divider()
    st.subheader("ğŸ“Š ç»“æ„åŒ–æ•°æ®æå–")
    
    if st.button("ğŸ” ä¸€é”®æå–å…³é”®äº‹ä»¶è¡¨", type="primary"):
        try:
            # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
            client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com"
            )
            
            # ä½¿ç”¨ RAG æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼ˆæ£€ç´¢æ›´å¤šç‰‡æ®µä»¥è·å–å®Œæ•´ä¿¡æ¯ï¼‰
            vectorstore = st.session_state.vectorstore
            # æ£€ç´¢æ›´å¤šç‰‡æ®µä»¥è·å–å®Œæ•´çš„äº‹ä»¶ä¿¡æ¯
            relevant_chunks = vectorstore.similarity_search("å…³é”®äº‹ä»¶ é£é™© åº”å¯¹æªæ–½", k=10)
            
            # æ„å»º Context
            context = "\n\n".join([chunk.page_content for chunk in relevant_chunks])
            
            # æ„å»ºç»“æ„åŒ–æå–çš„ System Prompt
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æå–åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»æ–‡æ¡£ä¸­æå–å…³é”®äº‹ä»¶ä¿¡æ¯ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„ JSON æ ¼å¼è¾“å‡ºã€‚

è¦æ±‚ï¼š
1. ä»”ç»†åˆ†ææ–‡æ¡£å†…å®¹ï¼Œè¯†åˆ«æ‰€æœ‰å…³é”®äº‹ä»¶
2. ä¸ºæ¯ä¸ªäº‹ä»¶è¯„ä¼°é£é™©ç­‰çº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
3. æå–æ ¸å¿ƒåº”å¯¹æªæ–½ï¼ˆä¸è¶…è¿‡20å­—ï¼‰
4. è®°å½•äº‹ä»¶æ‰€åœ¨çš„é¡µç ï¼ˆå¦‚æœæ–‡æ¡£ä¸­æœ‰é¡µç ä¿¡æ¯ï¼‰
5. **é‡è¦**ï¼šä¸ºæ¯ä¸ªäº‹ä»¶è¯„ä¼°ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆ1-10åˆ†ï¼‰ï¼Œå¹¶å¼•ç”¨åŸæ–‡ä¾æ®
   - å¦‚æœèƒ½åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°ç¡®åˆ‡çš„åŸæ–‡ä¾æ®ï¼Œç½®ä¿¡åº¦åº” >= 5
   - å¦‚æœæ‰¾ä¸åˆ°ç¡®åˆ‡åŸæ–‡æˆ–ä¿¡æ¯ä¸æ˜ç¡®ï¼Œç½®ä¿¡åº¦å¿…é¡» < 5
   - evidence_quote å¿…é¡»æ˜¯ä»æ–‡æ¡£ä¸­ç›´æ¥å¼•ç”¨çš„åŸè¯ï¼Œä¸èƒ½æ˜¯æ€»ç»“æˆ–æ”¹å†™

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»è¾“å‡ºçº¯ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—
- ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON Schema è¾“å‡ºï¼š

{
  "events": [
    {
      "event_name": "äº‹ä»¶åç§°",
      "risk_level": "é«˜/ä¸­/ä½",
      "key_action": "æ ¸å¿ƒåº”å¯¹æªæ–½(ä¸è¶…è¿‡20å­—)",
      "page_ref": é¡µç æ•°å­—æˆ–null,
      "confidence_score": 1-10çš„æ•´æ•°,
      "evidence_quote": "ä»æ–‡æ¡£ä¸­ç›´æ¥å¼•ç”¨çš„åŸæ–‡ä¾æ®"
    }
  ]
}

å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰äº‹ä»¶ä¿¡æ¯ï¼Œè¿”å›ç©ºæ•°ç»„ï¼š{"events": []}"""

            user_prompt = f"è¯·ä»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ä¸­æå–å…³é”®äº‹ä»¶ä¿¡æ¯ï¼š\n\n{context}"
            
            with st.spinner("ğŸ” æ­£åœ¨æå–å…³é”®äº‹ä»¶..."):
                # è°ƒç”¨ APIï¼Œæœ€å¤šé‡è¯•3æ¬¡
                max_retries = 3
                json_data = None
                
                for attempt in range(max_retries):
                    try:
                        response = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": user_prompt}
                            ],
                            temperature=0.1  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
                        )
                        
                        # è·å–å“åº”å†…å®¹
                        raw_response = response.choices[0].message.content.strip()
                        
                        # æ¸…ç†å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®°
                        raw_response = re.sub(r'```json\s*', '', raw_response)
                        raw_response = re.sub(r'```\s*', '', raw_response)
                        raw_response = raw_response.strip()
                        
                        # å°è¯•è§£æ JSON
                        json_data = json.loads(raw_response)
                        break  # æˆåŠŸè§£æï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                        
                    except json.JSONDecodeError as e:
                        if attempt < max_retries - 1:
                            st.warning(f"âš ï¸ JSON è§£æå¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                            continue
                        else:
                            st.error(f"âŒ JSON è§£æå¤±è´¥ï¼š{str(e)}")
                            st.code(raw_response, language="text")
                            raise
                    except Exception as e:
                        if attempt < max_retries - 1:
                            st.warning(f"âš ï¸ æå–å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                            continue
                        else:
                            raise
            
            # æ˜¾ç¤ºæå–ç»“æœ
            if json_data and "events" in json_data and len(json_data["events"]) > 0:
                st.success(f"âœ… æˆåŠŸæå– {len(json_data['events'])} ä¸ªå…³é”®äº‹ä»¶ï¼")
                
                # è½¬æ¢ä¸º DataFrame æ ¼å¼
                events_list = json_data["events"]
                df = pd.DataFrame(events_list)
                
                # ç¡®ä¿ confidence_score å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®¾ä¸ºé»˜è®¤å€¼
                if "confidence_score" not in df.columns:
                    df["confidence_score"] = 5  # é»˜è®¤å€¼
                
                # ç¡®ä¿ evidence_quote å­˜åœ¨
                if "evidence_quote" not in df.columns:
                    df["evidence_quote"] = "æœªæä¾›"
                
                # å¤„ç† confidence_score ä¸ºæ•°å€¼ç±»å‹
                df["confidence_score"] = pd.to_numeric(df["confidence_score"], errors="coerce").fillna(5)
                
                # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåºï¼Œä½¿å…¶æ›´æ˜“è¯»
                column_order = ["event_name", "risk_level", "key_action", "confidence_score", "evidence_quote"]
                if "page_ref" in df.columns:
                    column_order.insert(3, "page_ref")
                
                # åªä¿ç•™å­˜åœ¨çš„åˆ—
                available_columns = [col for col in column_order if col in df.columns]
                df = df[available_columns]
                
                # é‡å‘½ååˆ—åä¸ºä¸­æ–‡
                column_mapping = {
                    "event_name": "äº‹ä»¶åç§°",
                    "risk_level": "é£é™©ç­‰çº§",
                    "key_action": "æ ¸å¿ƒåº”å¯¹æªæ–½",
                    "page_ref": "é¡µç ",
                    "confidence_score": "ç½®ä¿¡åº¦",
                    "evidence_quote": "åŸæ–‡ä¾æ®"
                }
                df = df.rename(columns=column_mapping)
                
                # é…ç½®åˆ—æ˜¾ç¤ºæ ¼å¼
                column_config = {}
                
                # é…ç½®ç½®ä¿¡åº¦åˆ—ä¸ºè¿›åº¦æ¡
                if "ç½®ä¿¡åº¦" in df.columns:
                    column_config["ç½®ä¿¡åº¦"] = st.column_config.ProgressColumn(
                        "ç½®ä¿¡åº¦",
                        help="æ¨¡å‹å¯¹æå–å‡†ç¡®æ€§çš„ä¿¡å¿ƒè¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰",
                        min_value=1,
                        max_value=10,
                        format="%d åˆ†"
                    )
                
                # é…ç½®åŸæ–‡ä¾æ®åˆ—ï¼Œä½¿å…¶å¯ä»¥å±•å¼€æŸ¥çœ‹
                if "åŸæ–‡ä¾æ®" in df.columns:
                    column_config["åŸæ–‡ä¾æ®"] = st.column_config.TextColumn(
                        "åŸæ–‡ä¾æ®",
                        help="ä»æ–‡æ¡£ä¸­ç›´æ¥å¼•ç”¨çš„åŸæ–‡",
                        width="large"
                    )
                
                # åœ¨äº‹ä»¶åç§°åˆ—ä¸­æ·»åŠ è­¦å‘Šå›¾æ ‡ï¼ˆå¦‚æœç½®ä¿¡åº¦ä½ï¼‰
                if "ç½®ä¿¡åº¦" in df.columns and "äº‹ä»¶åç§°" in df.columns:
                    # ä¸ºä½ç½®ä¿¡åº¦çš„äº‹ä»¶æ·»åŠ è­¦å‘Šå›¾æ ‡
                    def add_warning_icon(row):
                        if pd.notna(row["ç½®ä¿¡åº¦"]) and row["ç½®ä¿¡åº¦"] < 7:
                            return f"âš ï¸ {row['äº‹ä»¶åç§°']}"
                        return row["äº‹ä»¶åç§°"]
                    
                    df["äº‹ä»¶åç§°"] = df.apply(add_warning_icon, axis=1)
                
                # æ˜¾ç¤ºè¡¨æ ¼
                st.dataframe(
                    df,
                    column_config=column_config,
                    use_container_width=True,
                    hide_index=True
                )
                
                # æ˜¾ç¤ºä½ç½®ä¿¡åº¦è­¦å‘Š
                if "ç½®ä¿¡åº¦" in df.columns:
                    low_confidence_df = df[df["ç½®ä¿¡åº¦"] < 7]
                    low_confidence_count = len(low_confidence_df)
                    if low_confidence_count > 0:
                        st.warning(f"âš ï¸ æœ‰ {low_confidence_count} ä¸ªäº‹ä»¶çš„ç½®ä¿¡åº¦ä½äº 7 åˆ†ï¼Œå·²ç”¨ âš ï¸ æ ‡è®°ï¼Œè¯·è°¨æ…å‚è€ƒã€‚")
                        # æ˜¾ç¤ºä½ç½®ä¿¡åº¦äº‹ä»¶çš„è¯¦ç»†ä¿¡æ¯
                        with st.expander(f"ğŸ” æŸ¥çœ‹ä½ç½®ä¿¡åº¦äº‹ä»¶è¯¦æƒ… ({low_confidence_count} ä¸ª)"):
                            for idx, row in low_confidence_df.iterrows():
                                st.markdown(f"**{row.get('äº‹ä»¶åç§°', 'æœªçŸ¥äº‹ä»¶').replace('âš ï¸ ', '')}**")
                                st.caption(f"ç½®ä¿¡åº¦: {row['ç½®ä¿¡åº¦']:.0f}/10")
                                if "åŸæ–‡ä¾æ®" in row and pd.notna(row["åŸæ–‡ä¾æ®"]):
                                    st.info(f"åŸæ–‡ä¾æ®: {row['åŸæ–‡ä¾æ®']}")
                                st.divider()
                
                # æ˜¾ç¤ºåŸå§‹ JSONï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
                with st.expander("ğŸ“‹ æŸ¥çœ‹åŸå§‹ JSON æ•°æ®"):
                    st.json(json_data)
            else:
                st.info("â„¹ï¸ æœªåœ¨æ–‡æ¡£ä¸­å‘ç°å…³é”®äº‹ä»¶ä¿¡æ¯ã€‚")
                
        except Exception as e:
            st.error(f"âŒ æå–è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

# æ˜¾ç¤ºå†å²èŠå¤©è®°å½•
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# èŠå¤©è¾“å…¥æ¡†
user_question = st.chat_input("å‘æ–‡æ¡£æé—®...")

# RAG é—®ç­”é€»è¾‘ï¼ˆå‘é‡æ£€ç´¢æ¨¡å¼ï¼‰
if user_question:
    # æ£€æŸ¥ API Key
    if not api_key:
        st.warning("âš ï¸ ç®¡ç†å‘˜æœªé…ç½®å¯†é’¥")
    # æ£€æŸ¥å‘é‡åº“æ˜¯å¦å­˜åœ¨
    elif "vectorstore" not in st.session_state:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶è§£æ PDF æ–‡æ¡£")
    else:
        try:
            # ä¿å­˜ç”¨æˆ·é—®é¢˜åˆ°å†å²è®°å½•
            st.session_state.messages.append({"role": "user", "content": user_question})
            
            # æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
            with st.chat_message("user"):
                st.write(user_question)
            
            # å‘é‡æ£€ç´¢ï¼šæ‰¾å‡ºæœ€ç›¸å…³çš„ 3 ä¸ªç‰‡æ®µ
            vectorstore = st.session_state.vectorstore
            relevant_chunks = vectorstore.similarity_search(user_question, k=3)
            
            # æ„å»º Contextï¼šæ‹¼æ¥æ£€ç´¢åˆ°çš„ç‰‡æ®µ
            context = "\n\n".join([chunk.page_content for chunk in relevant_chunks])
            
            # æ„å»º Prompt
            prompt = f"åŸºäºä»¥ä¸‹å‚è€ƒç‰‡æ®µå›ç­”é—®é¢˜ï¼š\n\n{context}\n\né—®é¢˜ï¼š{user_question}"
            
            # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆé€‚é… DeepSeekï¼‰
            client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com"
            )
            
            # è°ƒç”¨ DeepSeek API
            with st.chat_message("assistant"):
                with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­..."):
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "user", "content": prompt}
                        ]
                    )
                
                # è·å– AI å›ç­”
                ai_answer = response.choices[0].message.content
                
                # æ˜¾ç¤º AI å›ç­”
                st.write(ai_answer)
            
            # æ˜¾ç¤ºæ¥æºç‰‡æ®µï¼ˆåœ¨ AI å›ç­”ä¸‹æ–¹ï¼‰
            with st.expander("ğŸ” æŸ¥çœ‹ AI å‚è€ƒçš„æ–‡æ¡£ç‰‡æ®µ (Source Context)"):
                for i, chunk in enumerate(relevant_chunks, 1):
                    st.markdown(f"**ç‰‡æ®µ {i}:**")
                    st.info(chunk.page_content)
                    if i < len(relevant_chunks):
                        st.markdown("---")
            
            # ä¿å­˜ AI å›ç­”åˆ°å†å²è®°å½•
            st.session_state.messages.append({"role": "assistant", "content": ai_answer})
            
        except Exception as e:
            st.error(f"âŒ è°ƒç”¨ API æ—¶å‡ºé”™: {str(e)}")

